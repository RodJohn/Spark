# Spark Streaming

	高吞吐量的实时流处理器
	
# 工作机制

	Spark Streaming内部处理机制是：

	接受实时流的数据，并根据一定的时间间隔拆分成一批批的数据，
	然后通过Spark Engine处理这批数据，最终得到处理后的一批批结果数据。
	对应的批数据，在Spark内核对应一个RDD实例，因此，对应流数据的DStream可以看成是一组RDDs,即RDD的一个序列。


	Spark Streaming把实时输入数据流以时间片Δt （如1秒）为单位切分成块。
	Spark Streaming会把每块数据作为一个RDD，并使用RDD操作处理每一小块数据。
	每个块都会生成一个Spark Job处理，最终结果也返回多块


# 容错

	DStream基于RDD组成，RDD的容错性依旧有效，我们首先回忆一下SparkRDD的基本特性。

	1、RDD是一个不可变的、确定性的可重复计算的分布式数据集。RDD的某些partition丢失了，可以通过血统（lineage）信息重新计算恢复；
	2、如果RDD任何分区因worker节点故障而丢失，那么这个分区可以从原来依赖的容错数据集中恢复；
	3、由于Spark中所有的数据的转换操作都是基于RDD的，即使集群出现故障，只要输入数据集存在，所有的中间结果都是可以被计算的。

	Spark Streaming是可以从HDFS和S3这样的文件系统读取数据的，这种情况下所有的数据都可以被重新计算，不用担心数据的丢失。
	但是在大多数情况下，Spark Streaming是基于网络来接受数据的，
	此时为了实现相同的容错处理，在接受网络的数据时会在集群的多个Worker节点间进行数据的复制
	（默认的复制数是2），这导致产生在出现故障时被处理的两种类型的数据：
	
	1）Data received and replicated ：一旦一个Worker节点失效，系统会从另一份还存在的数据中重新计算。


	2）Data received but buffered for replication ：一旦数据丢失，可以通过RDD之间的依赖关系，从HDFS这样的外部文件系统读取数据。
	
	
