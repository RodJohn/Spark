# 伪分布式


# 环境

    jdk 1.8
    hadoop 2.6.5
    spark 2.3 on hadoop 2.6 
    scall
    
    
# 前期准备

    安装jdk    
    安装scala    
    安装hadoop  

# 安装spark

下载

    http://spark.apache.org/downloads.html
    选择合适的hadoop版本
    换个源
 

解压

    tar -zxvf spark-2.0.1-bin-hadoop2.6.tgz

# 配置

spark-env.sh

    cd spark/conf/
    cp spark-env.sh.template spark-env.sh
    vi spark-env.sh

    
    export JAVA_HOME= 
    SPARK_MASTER_HOST=msi
    
spark-defaults.conf

    cd spark/conf/
    cp spark-defaults.conf.template spark-defaults.conf
    vi spark-defaults.conf
     
    spark.master spark://msi:7077
    spark.local.dir /var/spark_shuffle

slaves

    cd spark/conf/
    cp slaves.template slaves
    vi slaves
     
    msi


# 简单控制

    启动
    $SPARK_HOME/sbin/start-all.sh
    
    停止
    $SPARK_HOME/sbin/stop-all.sh
    
# 测试 
    
    Web UI地址
    http://192.168.1.91:8080    